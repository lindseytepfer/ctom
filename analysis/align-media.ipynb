{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163026b9",
   "metadata": {},
   "source": [
    "VERSION REQUIREMENTS:\n",
    "\n",
    "* conda install numpy=1.22\n",
    "* conda install -c conda-forge librosa\n",
    "* pip install pydub\n",
    "* pip install sounddevice\n",
    "* pip install moviepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from glob import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_audio\n",
    "\n",
    "import sounddevice as sd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from scipy.signal import correlate, resample\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio, Video\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897a2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The following functions were written by Landry Bulls.\n",
    "See full code at https://github.com/LandryBulls/multidata/blob/main/alignment/align.py\n",
    "'''\n",
    "\n",
    "def extract_audio(posix_video_path):\n",
    "    out_audio_path = str(os.path.basename(str(posix_video_path)[:-4]+'.wav'))\n",
    "    ffmpeg_extract_audio(str(posix_video_path), out_audio_path)\n",
    "    # librosa returns the numpy array as well as the sample rate\n",
    "    loaded = librosa.load(out_audio_path, sr=None)\n",
    "    # delete the file\n",
    "    os.remove(out_audio_path)\n",
    "    # returns both the audio as a numpy array and the sample rate (arr, sr)\n",
    "    return loaded\n",
    "\n",
    "def mix_audio(list_of_arrays):\n",
    "    \"\"\"\n",
    "    Takes a list of numpy arrays and mixes them together, padding the shorter arrays with zeros.\n",
    "    \"\"\"\n",
    "    # find the longest array\n",
    "    max_len = max([len(arr) for arr in list_of_arrays])\n",
    "    # pad the shorter arrays with zeros\n",
    "    padded_arrays = [np.pad(arr, (0, max_len-len(arr)), 'constant') for arr in list_of_arrays]\n",
    "    # sum the arrays\n",
    "    return np.sum(padded_arrays, axis=0)\n",
    "\n",
    "def get_shift_values(list_of_camera_audio_arrays, microphone_mix):\n",
    "    \"\"\"\n",
    "    Takes a list of numpy arrays representing audio from each camera and a numpy array representing the microphone mix.\n",
    "    Returns a list of numpy arrays representing the aligned audio from each camera.\n",
    "    \"\"\"\n",
    "    # cross-correlate each audio stream with the mix\n",
    "    # the output array represents how similar the two signals are at each time step\n",
    "    all_arrays = list_of_camera_audio_arrays + [microphone_mix]\n",
    "\n",
    "    # find the longest array\n",
    "    max_pos = np.argmax(np.array([len(arr) for arr in all_arrays]))\n",
    "    maxlen = len(all_arrays[max_pos])\n",
    "    del all_arrays\n",
    "\n",
    "    # pad the shorter arrays with zeros    \n",
    "    list_of_camera_audio_arrays = [np.pad(arr, (0, maxlen-len(arr)), 'constant') for arr in list_of_camera_audio_arrays]\n",
    "    microphone_mix = np.pad(microphone_mix, (0, maxlen-len(microphone_mix)), 'constant')\n",
    "\n",
    "    # cross-correlate each array with the microphone mix\n",
    "    print(\"Cross-correlating audio streams with microphone mix...\\n\")\n",
    "    correlations = [correlate(arr, microphone_mix, mode='full') for arr in list_of_camera_audio_arrays]\n",
    "\n",
    "    # find the time shift (in seconds) that maximizes the correlation\n",
    "    print(\"Finding time shift that maximizes correlation...\\n\")\n",
    "    shifts = [np.argmax(corr) - len(arr) for corr, arr in zip(correlations, list_of_camera_audio_arrays)]\n",
    "    for s, shift in enumerate(shifts):\n",
    "        print(f'Shift {s}: {shift} samples')\n",
    "    return shifts\n",
    "\n",
    "def trim_video(posix_video_path, start_time, end_time, output_path):\n",
    "    \"\"\"\n",
    "    Takes a posix path to a video file, a start trim value (in seconds), an end trim value (in seconds), and an output path.\n",
    "    Trims the video and saves it to the output path.\n",
    "    \"\"\"\n",
    "    stringPath = str(posix_video_path)\n",
    "    duration = VideoFileClip(stringPath).duration\n",
    "    ffmpeg_command = f'ffmpeg -i {stringPath} -ss {start_time} -to {end_time} -c copy {output_path}' ###\n",
    "    subprocess.run(ffmpeg_command, shell=True)\n",
    "\n",
    "def trim_audio(posix_audio_path, start_time, end_time, output_path):\n",
    "    \"\"\"\n",
    "    Takes a posix path to an audio file, a start trim value (in seconds), an end trim value (in seconds), and an output path.\n",
    "    Trims the audio and saves it to the output path.\n",
    "    \"\"\"\n",
    "    stringPath = str(posix_audio_path)\n",
    "    duration = librosa.get_duration(filename=stringPath)\n",
    "    ffmpeg_command = f'ffmpeg -i {stringPath} -ss {start_time} -to {end_time} -c copy {output_path}'\n",
    "    subprocess.run(ffmpeg_command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05a6710",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "data_dir = os.listdir(path)\n",
    "pairlist = [x for x in data_dir if 'pair-' in x]\n",
    "pairlist.sort() #pair-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f927075",
   "metadata": {},
   "source": [
    "# <font color='deeppink'>Aligning audio and brio files.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec033135",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair in pairlist:\n",
    "    print(\"starting pair: \", pair)\n",
    "\n",
    "    try:\n",
    "        pair_path = path+pair+os.sep\n",
    "        derivative_path = pair_path+\"derivatives\"\n",
    "        \n",
    "        audio_list = os.listdir(pair_path+\"audio/\")\n",
    "        audio_paths = [pair_path+\"audio/\"+x for x in audio_list if \".WAV\" in x]\n",
    "        \n",
    "        #gopro_file = pair_path+\"gopro/gopro_concatenated.mp4\"\n",
    "        \n",
    "        brio_list = os.listdir(pair_path+\"brio/\")\n",
    "        video_paths = [pair_path+\"brio/\"+x for x in brio_list]\n",
    "        \n",
    "        #video_paths.append(gopro_file)\n",
    "        \n",
    "        # make mix of all mics\n",
    "        print(\"Starting the mixing process...\")\n",
    "        mic_mix = mix_audio([librosa.load(mic, sr=None)[0] for mic in audio_paths])\n",
    "        mic_audio_sr = librosa.load(audio_paths[0], sr=None)[1]\n",
    "        print(\"Mix created.\")\n",
    "        \n",
    "        # extract audio from video files\n",
    "        print(\"Extracting audio from video files...\\n\")\n",
    "        video_audio = [extract_audio(vid) for vid in video_paths]\n",
    "        video_audio_sr = video_audio[0][1]\n",
    "        video_audio = [i[0] for i in video_audio]   \n",
    "        print(\"Audio extracted!\")\n",
    "\n",
    "        assert mic_audio_sr == video_audio_sr, \"Sample rates of audio files do not match.\"\n",
    "\n",
    "        # get durations of video files\n",
    "        print(\"Getting durations of video files...\\n\")\n",
    "        video_durations = dict(zip(video_paths, [VideoFileClip(str(vid)).duration for vid in video_paths]))\n",
    "        audio_duration = mic_mix.shape[0]/mic_audio_sr\n",
    "\n",
    "        # get shift values\n",
    "        print(\"Getting shift values...\\n\")\n",
    "        shift_values = get_shift_values(video_audio, mic_mix)\n",
    "\n",
    "        # check distribution of positive and negative shifts\n",
    "        if all([shift > 0 for shift in shift_values]):\n",
    "            trim_status = 'early'\n",
    "        elif all([shift < 0 for shift in shift_values]):\n",
    "            trim_status = 'late'\n",
    "        else:\n",
    "            trim_status = 'mixed'\n",
    "\n",
    "        start_end_keys = dict(zip(['in', 'out'], [[], []]))\n",
    "        all_files = video_paths + ['audio_trim']\n",
    "        trim_times = {}\n",
    "        for file in all_files:\n",
    "            trim_times[file] = start_end_keys.copy()\n",
    "        trim_times['audio_trim'] = start_end_keys.copy()\n",
    "            \n",
    "        if trim_status == 'early':\n",
    "            # trim the beginning of the video files\n",
    "            for vid, shift in zip(video_paths, shift_values):\n",
    "                trim_amount = shift/video_audio_sr\n",
    "                trim_times[vid]['in'] = trim_amount\n",
    "                video_durations[vid] = video_durations[vid] - trim_amount\n",
    "                \n",
    "            trim_times['audio_trim']['in'] = 0\n",
    "        \n",
    "        elif trim_status == 'late':\n",
    "            # trim the end of the video files\n",
    "            latest = min(shift_values)\n",
    "            \n",
    "            for vid, shift in zip(video_paths, shift_values):\n",
    "                if shift == latest:\n",
    "                    trim_times[vid]['in'] = 0\n",
    "                else:\n",
    "                    trim_amount = (abs(latest) - abs(shift))/video_audio_sr\n",
    "                    trim_times[vid]['in'] = trim_amount\n",
    "                    video_durations[vid] = video_durations[vid] - trim_amount\n",
    "            \n",
    "            audio_trim = abs(latest)/mic_audio_sr\n",
    "            trim_times['audio_trim']['in'] = audio_trim\n",
    "            audio_duration = audio_duration - audio_trim\n",
    "        \n",
    "        elif trim_status == 'mixed':\n",
    "            latest = min(shift_values)\n",
    "            for vid, shift in zip(video_paths, shift_values):\n",
    "                if shift == latest:\n",
    "                    trim_times[vid]['in'] = 0\n",
    "                elif shift > 0:\n",
    "                    trim_amount = (abs(shift)+abs(latest))/video_audio_sr\n",
    "                    trim_times[vid]['in'] = trim_amount\n",
    "                    video_durations[vid] = video_durations[vid] - trim_amount\n",
    "                else:\n",
    "                    trim_amount = (abs(latest) - abs(shift))/video_audio_sr\n",
    "                    trim_times[vid]['in'] = trim_amount\n",
    "                    video_durations[vid] = video_durations[vid] - trim_amount\n",
    "            \n",
    "            audio_trim = abs(latest)/mic_audio_sr\n",
    "            trim_times['audio_trim']['in'] = audio_trim\n",
    "            audio_duration = audio_duration - audio_trim\n",
    "        \n",
    "        # get ending trim times\n",
    "        all_durations = list(video_durations.values()) + [audio_duration]    \n",
    "        shortest = min(all_durations)\n",
    "        for file in trim_times.keys():\n",
    "            trim_times[file]['out'] = shortest + trim_times[file]['in']\n",
    "            \n",
    "        # trim the video files\n",
    "        print(\"Trimming video files...\\n\")\n",
    "        # all the trim times are in seconds\n",
    "        for vid in video_paths:\n",
    "            trim_video(vid, trim_times[vid]['in'], trim_times[vid]['out'], str(derivative_path+os.sep+f'{os.path.basename(str(vid))[:-4]}_trimmed.mp4'))\n",
    "            \n",
    "        # trim the audio files\n",
    "        print(\"Trimming audio files...\\n\")\n",
    "        for mic in audio_paths:\n",
    "            trim_audio(mic, trim_times['audio_trim']['in'], trim_times['audio_trim']['out'], str(derivative_path+os.sep+f'{os.path.basename(str(mic))[:-4]}_trimmed.wav'))\n",
    "\n",
    "        # print out all the trim times per file\n",
    "        print(\"Trim times:\\n\")\n",
    "        for file in trim_times.keys():\n",
    "            print(f\"{file}: {trim_times[file]['in']}s to {trim_times[file]['out']}s\")\n",
    "\n",
    "        print(\"DONE!\")\n",
    "    \n",
    "    except:\n",
    "        print(\"SOMETHING is amiss\")\n",
    "        continue\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "align-media",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
